backend: theano
class_name: Sequential
config:
- class_name: Embedding
  config:
    activity_regularizer: null
    batch_input_shape: !!python/tuple [null, 300]
    dtype: float32
    embeddings_constraint: null
    embeddings_initializer:
      class_name: RandomUniform
      config: {maxval: 0.05, minval: -0.05, seed: null}
    embeddings_regularizer: null
    input_dim: 53
    input_length: 300
    mask_zero: false
    name: embedding_1
    output_dim: 300
    trainable: true
- class_name: Bidirectional
  config:
    layer:
      class_name: LSTM
      config:
        activation: tanh
        activity_regularizer: null
        bias_constraint: null
        bias_initializer:
          class_name: Zeros
          config: {}
        bias_regularizer: null
        dropout: 0.0
        go_backwards: false
        implementation: 1
        kernel_constraint: null
        kernel_initializer:
          class_name: VarianceScaling
          config: {distribution: uniform, mode: fan_avg, scale: 1.0, seed: null}
        kernel_regularizer: null
        name: lstm_1
        recurrent_activation: hard_sigmoid
        recurrent_constraint: null
        recurrent_dropout: 0.0
        recurrent_initializer:
          class_name: Orthogonal
          config: {gain: 1.0, seed: null}
        recurrent_regularizer: null
        return_sequences: true
        return_state: false
        stateful: false
        trainable: true
        unit_forget_bias: true
        units: 100
        unroll: false
        use_bias: true
    merge_mode: concat
    name: bidirectional_1
    trainable: true
- class_name: Bidirectional
  config:
    layer:
      class_name: LSTM
      config:
        activation: tanh
        activity_regularizer: null
        bias_constraint: null
        bias_initializer:
          class_name: Zeros
          config: {}
        bias_regularizer: null
        dropout: 0.0
        go_backwards: false
        implementation: 1
        kernel_constraint: null
        kernel_initializer:
          class_name: VarianceScaling
          config: {distribution: uniform, mode: fan_avg, scale: 1.0, seed: null}
        kernel_regularizer: null
        name: lstm_2
        recurrent_activation: hard_sigmoid
        recurrent_constraint: null
        recurrent_dropout: 0.0
        recurrent_initializer:
          class_name: Orthogonal
          config: {gain: 1.0, seed: null}
        recurrent_regularizer: null
        return_sequences: false
        return_state: false
        stateful: false
        trainable: true
        unit_forget_bias: true
        units: 100
        unroll: false
        use_bias: true
    merge_mode: concat
    name: bidirectional_2
    trainable: true
- class_name: Dense
  config:
    activation: softmax
    activity_regularizer: null
    bias_constraint: null
    bias_initializer:
      class_name: Zeros
      config: {}
    bias_regularizer: null
    kernel_constraint: null
    kernel_initializer:
      class_name: VarianceScaling
      config: {distribution: uniform, mode: fan_avg, scale: 1.0, seed: null}
    kernel_regularizer: null
    name: dense_1
    trainable: true
    units: 5
    use_bias: true
keras_version: 2.2.0
